{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocn9j56OC-tJ"
      },
      "source": [
        "# Model Prototyping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Tsi6DtVC-tO"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install textacy\n",
        "!pip install wandb\n",
        "!pip install optuna"
      ],
      "metadata": {
        "id": "y6fXf54LSND0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rXI-gSqC-tP"
      },
      "outputs": [],
      "source": [
        "# Data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Utilities\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Machine learning\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# PyTorch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Transformers\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# Hyperparameters optimization\n",
        "import optuna\n",
        "import wandb\n",
        "import joblib\n",
        "\n",
        "\n",
        "# Google drive files for data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU used \n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "g9OvryARNRY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJXsBwFpC-tR"
      },
      "source": [
        "## Prototyping using huggingface transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adm6JpARC-tS"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False, normalization=True)\n",
        "\n",
        "# INPUT TWEET IS ALREADY NORMALIZED!\n",
        "line = \"SC has first two presumptive cases of coronavirus , DHEC confirms HTTPURL via @USER :cry:\"\n",
        "\n",
        "input_ids = torch.tensor([tokenizer(line, padding=\"max_length\", max_length=64, truncation=True).input_ids])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check for how many tokens we'll need"
      ],
      "metadata": {
        "id": "XsThsTjbN0Yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Machine Learning/Datasets/Disaster Tweets/train.csv\")"
      ],
      "metadata": {
        "id": "0NELkE7DOQBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max = 0 \n",
        "for text in data['text']:\n",
        "  input_ids = tokenizer(text).input_ids\n",
        "  max = np.max((max, len(input_ids)))"
      ],
      "metadata": {
        "id": "GVVnNv55OJtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(max)"
      ],
      "metadata": {
        "id": "SartX8ySP8BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the maximum number of tokens is 64, to take into account the fact that tweets from the test set may be longer, we'll set the max number of tokens to 90, this will speed the training."
      ],
      "metadata": {
        "id": "Wv1qTacAQCXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = tokenizer.encode(line)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "c9ACBchSLttN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dict = tokenizer.encode_plus(line, add_special_tokens=True, max_length=90, padding='max_length', return_attention_mask=True, return_tensors='pt')\n",
        "input_ids = output_dict.input_ids\n",
        "attention_mask = output_dict.attention_mask"
      ],
      "metadata": {
        "id": "sTlVx4NjSEjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids"
      ],
      "metadata": {
        "id": "H8KzTZq8TRR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask"
      ],
      "metadata": {
        "id": "44kalQSPTShW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data prep"
      ],
      "metadata": {
        "id": "mMREaLKpRvmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import html\n",
        "import re\n",
        "\n",
        "# define clean function\n",
        "# add / remove any line if necessary\n",
        "def clean(text):\n",
        "    # convert html escapes like &amp; by their plain-text representation\n",
        "    text = html.unescape(text) \n",
        "    \n",
        "    # subsitute tags like <tab> by spaces in the specified text or remove them\n",
        "    text = re.sub(r'<[^<>]*>', ' ', text)\n",
        "    \n",
        "    # subsitute markdown URLs like [Some text](https://....)\n",
        "    text = re.sub(r'\\[([^\\[\\]]*)\\]\\([^\\(\\)]*\\)', r'\\1', text)\n",
        "    \n",
        "    # subsitute text or code in brackets like [0]\n",
        "    text = re.sub(r'\\[[^\\[\\]]*\\]', ' ', text)\n",
        "    \n",
        "    # subsitute standalone sequences of specials, matches &# but NOT #hashtag\n",
        "    text = re.sub(r'(?:^|\\s)[&#<>{}\\[\\]+|\\\\:-]{1,}(?:\\s|$)', ' ', text)\n",
        "\n",
        "     # subsitute standalone sequences of hyphens like --- or ==\n",
        "    text = re.sub(r'(?:^|\\s)[\\-=\\+]{2,}(?:\\s|$)', ' ', text)\n",
        "    \n",
        "    # sequences of white spaces\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    \n",
        "    #remove stock market tickers like $GE\n",
        "    text = re.sub(r'\\$\\w*', '', text)  \n",
        "    \n",
        "    #remove old style retweet text \"RT\"\n",
        "    text = re.sub(r'RT[\\s]+', '', text)        \n",
        "    text = re.sub(r'DT[\\s]+', '', text)   \n",
        "    \n",
        "    #remove hashtags\n",
        "    text = re.sub(r'#', '', text)\n",
        "    \n",
        "    return text.strip()"
      ],
      "metadata": {
        "id": "RNaQUl6MRygi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textacy import preprocessing\n",
        "from functools import partial\n",
        "\n",
        "# create cleaning pipeline\n",
        "preproc = preprocessing.make_pipeline(\n",
        "    \n",
        "    # join words split by a hyphen or line break\n",
        "    preprocessing.normalize.hyphenated_words,\n",
        "    \n",
        "    # subsitute fancy quatation marks with an ASCII equivalent\n",
        "    preprocessing.normalize.quotation_marks,\n",
        "    \n",
        "    # normalize unicode characters in text into canonical forms\n",
        "    preprocessing.normalize.unicode,\n",
        "    \n",
        "    # remove any accents character in text by replacing them with ASCII equivalents or removing them entirely\n",
        "    preprocessing.remove.accents,\n",
        "\n",
        "    # remove all email addresses in text \n",
        "    partial(preprocessing.replace.emails, repl= \"\"), # or _EMAIL_\n",
        "    \n",
        "    # remove all phone numbers in text \n",
        "    partial(preprocessing.replace.phone_numbers, repl=\"\"), # or _PhoneNumber_\n",
        "    \n",
        "    # remove all URLs in text \n",
        "    partial(preprocessing.replace.urls, repl= \"\"), # or _URL_\n",
        "    \n",
        "    # remove all (Twitter-style) user handles in text \n",
        "    partial(preprocessing.replace.user_handles, repl=\"\"), # or _HANDLE_\n",
        "    \n",
        "    # Replace all hashtags in text with repl.\n",
        "    #partial(preprocessing.replace.hashtags, repl=\"_HASTAG_\"),\n",
        "    \n",
        "    ### TEST ### Enable it only before generating tokens for word clouds\n",
        "    partial(preprocessing.replace.numbers, repl=\"\"),\n",
        "    \n",
        "    # remove HTML tags from text\n",
        "    preprocessing.remove.html_tags,\n",
        "\n",
        "    # remove text within curly {}, square [], and/or round () brackets\n",
        "    preprocessing.remove.brackets,\n",
        "\n",
        "    # replace specific set of punctuation marks with whitespace\n",
        "    partial(preprocessing.remove.punctuation, only=[ \",\", \":\", \";\", \"/\", \" \",\"(\",\"@\"]),\n",
        "    \n",
        "    # Replace all currency symbols in text with repl\n",
        "    preprocessing.replace.currency_symbols,\n",
        "    \n",
        "    # replace all emoji and pictographs in text with repl.\n",
        "    preprocessing.replace.emojis,\n",
        "    \n",
        " )"
      ],
      "metadata": {
        "id": "BMVlh7dFR32D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "data['text_c'] = data['text'].apply(clean)\n",
        "data['text_clean'] = data['text_c'].apply(preproc)\n",
        "data['text_clean'] = data['text_clean'].str.lower()"
      ],
      "metadata": {
        "id": "BAMccJNkSAU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "tweets = data['text'].to_list()\n",
        "\n",
        "for tweet in tweets:\n",
        "  output_dict = tokenizer.encode_plus(tweet, add_special_tokens=True, max_length=90, padding='max_length', return_attention_mask=True, return_tensors='pt')\n",
        "  input_ids.append(output_dict.input_ids)\n",
        "  attention_masks.append(output_dict.attention_mask)\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "labels = torch.tensor(data['target'].values)"
      ],
      "metadata": {
        "id": "9nf85aqHUwvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
        "\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)"
      ],
      "metadata": {
        "id": "73yv1aTKDx_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_size = int(0.85 * len(dataset)) # 85 - 15 % split\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "batch_size = 32 # Bigger values will increase the gradient precision, lower values will reduce the memory load\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle = True)"
      ],
      "metadata": {
        "id": "3cb3C8CzUJnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training on all samples\n",
        "train_dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = True)"
      ],
      "metadata": {
        "id": "nmPzrCucD0ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters optimization"
      ],
      "metadata": {
        "id": "p9XnBWIutyx4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we are going to find the hyperparameters which reduce the val loss the most"
      ],
      "metadata": {
        "id": "h8oSjNZryDs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define model inside this function, the archicture can be optimized with optuna\n",
        "def define_model(trial):\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\"vinai/bertweet-base\", num_labels = 2, output_attentions = False, output_hidden_states = False)  \n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "lO73MwNPtyDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_optuna(model, optimizer, scheduler, train_dataloader, trial, device = 'cpu', val_dataloader = None, epochs = 10):\n",
        "  pbar = tqdm(range(epochs))\n",
        "\n",
        "  metrics = {\n",
        "    \"epochs\" : [],\n",
        "    \"train_losses\" : [],\n",
        "    \"val_losses\" : [],\n",
        "    \"val_accs\" : [],\n",
        "    \"lr\" : [],\n",
        "  }\n",
        "\n",
        "  for i, epoch in enumerate(pbar):\n",
        "    model.train()\n",
        "\n",
        "    total_train_loss = 0\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "\n",
        "      input_ids = batch[0].to(device)\n",
        "      input_masks = batch[1].to(device)\n",
        "      labels = batch[2].to(device)\n",
        "\n",
        "      model.zero_grad()\n",
        "\n",
        "      result = model(input_ids, token_type_ids = None, attention_mask = input_masks, labels = labels, return_dict = True)\n",
        "\n",
        "      loss = result.loss\n",
        "      logits = result.logits\n",
        "\n",
        "      total_train_loss += loss.item()\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      # Call to scheduler only if it's linear\n",
        "      scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    total_val_acc = 0\n",
        "    total_val_loss = 0\n",
        "    \n",
        "    if val_dataloader is not None:\n",
        "\n",
        "      model.eval()\n",
        "      for i, batch in enumerate(val_dataloader):\n",
        "\n",
        "        input_ids = batch[0].to(device)\n",
        "        input_masks = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "          result = model(input_ids, token_type_ids = None, attention_mask = input_masks, labels = labels, return_dict = True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits.detach().cpu().numpy()\n",
        "        labels = labels.cpu().numpy()\n",
        "\n",
        "        preds = np.argmax(logits, axis = 1).flatten()\n",
        "        labels = labels.flatten()\n",
        "\n",
        "        val_acc = np.sum(preds == labels) / len(labels)\n",
        "\n",
        "        total_val_acc += val_acc\n",
        "        total_val_loss += loss.item()\n",
        "    \n",
        "      avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "      avg_val_acc = total_val_acc / len(val_dataloader)\n",
        "\n",
        "    metrics['lr'].append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    # Call to scheduler only if it's reduce on plateau\n",
        "    # scheduler.step(avg_val_loss)\n",
        "\n",
        "    metrics['epochs'].append(epoch)\n",
        "    metrics['train_losses'].append(avg_train_loss)\n",
        "\n",
        "    #if val_dataloader is not None :\n",
        "    # metrics['val_losses'].append(avg_val_loss)\n",
        "    # metrics['val_accs'].append(avg_val_acc)\n",
        "    # pbar.set_postfix({'train_loss': avg_train_loss, 'val_loss': avg_val_loss, 'val_acc' : avg_val_acc})\n",
        "\n",
        "    if trial is not None:\n",
        "      trial.report(metrics['val_losses'], epoch)\n",
        "\n",
        "      # Report metrics to wandb\n",
        "      wandb.log(data = metrics, step = epoch)\n",
        "\n",
        "      if trial.should_prune():\n",
        "        wandb.run.summary['state'] = \"pruned\"\n",
        "        wandb.finish(quiet = True)\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "      # Saving the fine tunned model\n",
        "      ckpt = {\n",
        "          'epoch' : epoch,\n",
        "          'model_state' : model.state_dict(),\n",
        "          'optimizer_state' : optimizer.state_dict()\n",
        "      }\n",
        "\n",
        "  return model, metrics"
      ],
      "metadata": {
        "id": "-A9Xg7x91ZbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def objective(trial):\n",
        "  \n",
        "    # Generate the model\n",
        "    model = define_model(trial).to(device) \n",
        "\n",
        "    # Define learning components (to be used in learning function)\n",
        "    lr = trial.suggest_float(\"lr\", 1e-8, 5e-5)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr = lr, betas = (0.9, 0.999), eps = 1e-8)\n",
        "\n",
        "    epochs = trial.suggest_int(\"epoch\", 1, 5)\n",
        "\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    num_warmup_steps = trial.suggest_int(\"warmup_steps\", 0, int(0.1 * total_steps))\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = num_warmup_steps, num_training_steps = total_steps)\n",
        "    \n",
        "    # init tracking with wandb\n",
        "    config = dict(trial.params)\n",
        "    config['trial.number'] = trial.number\n",
        "    wandb.init(\n",
        "        project=\"twitter_disaster_tweets\",\n",
        "        entity=\"saulofein\",\n",
        "        config=config,\n",
        "        group=tag,\n",
        "        reinit=True        \n",
        "    )\n",
        "    \n",
        "    # Learning\n",
        "    model, metrics = train_model_optuna(model, optimizer, scheduler, train_dataloader, trial, val_dataloader = val_dataloader, device = device, epochs = epochs)\n",
        "    \n",
        "    # Compute the metrics Optuna will try to otpimize (maximize or minimize)\n",
        "    val_loss = metrics.val_losses[-1]\n",
        "    \n",
        "    # Report the RMSE to wandb\n",
        "    wandb.run.summary['val_loss'] = val_loss\n",
        "    wandb.run.summary['state'] = 'completed'\n",
        "    wandb.finish(quiet = True)\n",
        "    \n",
        "    return val_loss"
      ],
      "metadata": {
        "id": "EAxjnh-KxZVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag = 'bert_1'\n",
        "\n",
        "study = optuna.create_study(direction = \"minimize\", study_name = tag)\n",
        "study.optimize(objective, n_trials = 100)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best trial :\")\n",
        "best_trial = study.best_trial\n",
        "print(\"  Value :\", best_trial.value)\n",
        "print(\"  Params:\")\n",
        "for key, value in best_trial.params.items():\n",
        "    print(f\"    {key} : {value}\")\n",
        "\n",
        "# Importance of hyperparameters\n",
        "importance_dict = optuna.importance.get_param_importances(study = study)\n",
        "plt.figure(figsize = (20, 15))\n",
        "sns.barplot(x = list(importance_dict.values()), y = list(importance_dict.keys()))\n",
        "plt.savefig(os.path.join(\"..\", \"hyperparameters_importance_{}.png\".format(tag.split('_')[1])))\n",
        "\n",
        "# Save best parameters dict\n",
        "joblib.dump(best_trial.params, os.path.join(os.getcwd(), \"..\", \"best_params\", f\"best_params_{tag}.pkl\"))"
      ],
      "metadata": {
        "id": "IhIWHLOdxsLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "4bcyjZJ3kazZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"vinai/bertweet-base\", num_labels = 2, output_attentions = False, output_hidden_states = False)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "LvqK2hOeZlK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 5e-6, betas = (0.9, 0.999), eps = 1e-8)"
      ],
      "metadata": {
        "id": "oB0OA1cxbUZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "def train_model(model, optimizer, scheduler, train_dataloader, val_dataloader = None, epochs = 10):\n",
        "  pbar = tqdm(range(epochs))\n",
        "\n",
        "  metrics = {\n",
        "    \"epochs\" : [],\n",
        "    \"train_losses\" : [],\n",
        "    \"val_losses\" : [],\n",
        "    \"val_accs\" : [],\n",
        "    \"lr\" : [],\n",
        "  }\n",
        "\n",
        "  for i, epoch in enumerate(pbar):\n",
        "    model.train()\n",
        "\n",
        "    total_train_loss = 0\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "\n",
        "      input_ids = batch[0].to(device)\n",
        "      input_masks = batch[1].to(device)\n",
        "      labels = batch[2].to(device)\n",
        "\n",
        "      model.zero_grad()\n",
        "\n",
        "      result = model(input_ids, token_type_ids = None, attention_mask = input_masks, labels = labels, return_dict = True)\n",
        "\n",
        "      loss = result.loss\n",
        "      logits = result.logits\n",
        "\n",
        "      total_train_loss += loss.item()\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      # Call to scheduler only if it's linear\n",
        "      scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    total_val_acc = 0\n",
        "    total_val_loss = 0\n",
        "    \n",
        "    if val_dataloader is not None:\n",
        "\n",
        "      model.eval()\n",
        "      for i, batch in enumerate(val_dataloader):\n",
        "\n",
        "        input_ids = batch[0].to(device)\n",
        "        input_masks = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "          result = model(input_ids, token_type_ids = None, attention_mask = input_masks, labels = labels, return_dict = True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits.detach().cpu().numpy()\n",
        "        labels = labels.cpu().numpy()\n",
        "\n",
        "        preds = np.argmax(logits, axis = 1).flatten()\n",
        "        labels = labels.flatten()\n",
        "\n",
        "        val_acc = np.sum(preds == labels) / len(labels)\n",
        "\n",
        "        total_val_acc += val_acc\n",
        "        total_val_loss += loss.item()\n",
        "    \n",
        "      avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "      avg_val_acc = total_val_acc / len(val_dataloader)\n",
        "\n",
        "    metrics['lr'].append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    # Call to scheduler only if it's reduce on plateau\n",
        "    # scheduler.step(avg_val_loss)\n",
        "\n",
        "    metrics['epochs'].append(epoch)\n",
        "    metrics['train_losses'].append(avg_train_loss)\n",
        "\n",
        "    if val_dataloader is not None :\n",
        "      metrics['val_losses'].append(avg_val_loss)\n",
        "      metrics['val_accs'].append(avg_val_acc)\n",
        "      pbar.set_postfix({'train_loss': avg_train_loss, 'val_loss': avg_val_loss, 'val_acc' : avg_val_acc})\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "      # Saving the fine tunned model\n",
        "      ckpt = {\n",
        "          'epoch' : epoch,\n",
        "          'model_state' : model.state_dict(),\n",
        "          'optimizer_state' : optimizer.state_dict()\n",
        "      }\n",
        "      torch.save(ckpt, \"/content/drive/MyDrive/Machine Learning/Models/weights_bertweet_intermediate.pt\")\n",
        "\n",
        "  # Saving the fine tunned model\n",
        "  ckpt = {\n",
        "          'epoch' : epoch,\n",
        "          'model_state' : model.state_dict(),\n",
        "          'optimizer_state' : optimizer.state_dict()\n",
        "      }\n",
        "  torch.save(ckpt, \"/content/drive/MyDrive/Machine Learning/Models/weights_bertweet_final.pt\")\n",
        "\n",
        "  return model, metrics"
      ],
      "metadata": {
        "id": "1ppga7Vybx2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# scheduler = ReduceLROnPlateau(optimizer, mode = 'min', patience = 5)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)\n",
        "\n",
        "model, metrics = train_model(model, optimizer, scheduler, train_dataloader, epochs = epochs)"
      ],
      "metadata": {
        "id": "kgaXDCEKH7_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18, 6))\n",
        "plt.subplot(1, 3, 1)\n",
        "\n",
        "plt.plot(metrics['train_losses'], label='train loss')\n",
        "plt.plot(metrics['val_losses'], label='val loss')\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(metrics['val_accs'], label='val acc')\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(metrics['lr'], label='lr')\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend()\n",
        "plt.title('Learning rate')"
      ],
      "metadata": {
        "id": "p5TRgAyukeid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_confusion_heatmap(\n",
        "        cf,\n",
        "        group_names=None,\n",
        "        categories=\"auto\",\n",
        "        count=True,\n",
        "        percent=True,\n",
        "        cbar=True,\n",
        "        xyticks=True,\n",
        "        xyplotlabels=True,\n",
        "        sum_stats=True,\n",
        "        figsize=None,\n",
        "        cmap=\"Blues\",\n",
        "        title=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
        "    Arguments\n",
        "    ---------\n",
        "    cf:            confusion matrix to be passed in\n",
        "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
        "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
        "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
        "    normalize:     If True, show the proportions for each category. Default is True.\n",
        "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
        "                   Default is True.\n",
        "    xyticks:       If True, show x and y ticks. Default is True.\n",
        "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
        "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
        "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
        "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
        "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "\n",
        "    title:         Title for the heatmap. Default is None.\n",
        "    \"\"\"\n",
        "\n",
        "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
        "    blanks = [\"\" for i in range(cf.size)]\n",
        "\n",
        "    if group_names and len(group_names) == cf.size:\n",
        "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
        "    else:\n",
        "        group_labels = blanks\n",
        "\n",
        "    if count:\n",
        "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
        "    else:\n",
        "        group_counts = blanks\n",
        "\n",
        "    if percent:\n",
        "        group_percentages = [\n",
        "            \"{0:.2%}\".format(value) for value in cf.flatten() / np.sum(cf)\n",
        "        ]\n",
        "    else:\n",
        "        group_percentages = blanks\n",
        "\n",
        "    box_labels = [\n",
        "        f\"{v1}{v2}{v3}\".strip()\n",
        "        for v1, v2, v3 in zip(group_labels, group_counts, group_percentages)\n",
        "    ]\n",
        "    box_labels = np.asarray(box_labels).reshape(cf.shape[0], cf.shape[1])\n",
        "\n",
        "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
        "    if sum_stats:\n",
        "        # Accuracy is sum of diagonal divided by total observations\n",
        "        accuracy = np.trace(cf) / float(np.sum(cf))\n",
        "\n",
        "        # if it is a binary confusion matrix, show some more stats\n",
        "        if len(cf) == 2:\n",
        "            # Metrics for Binary Confusion Matrices\n",
        "            precision = cf[1, 1] / sum(cf[:, 1])\n",
        "            recall = cf[1, 1] / sum(cf[1, :])\n",
        "            f1_score = 2 * precision * recall / (precision + recall)\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
        "                accuracy, precision, recall, f1_score\n",
        "            )\n",
        "        else:\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
        "    else:\n",
        "        stats_text = \"\"\n",
        "\n",
        "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
        "    if figsize == None:\n",
        "        # Get default figure size if not set\n",
        "        figsize = plt.rcParams.get(\"figure.figsize\")\n",
        "\n",
        "    if xyticks == False:\n",
        "        # Do not show categories if xyticks is False\n",
        "        categories = False\n",
        "\n",
        "    # MAKE THE HEATMAP VISUALIZATION\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.heatmap(\n",
        "        cf,\n",
        "        annot=box_labels,\n",
        "        fmt=\"\",\n",
        "        cmap=cmap,\n",
        "        cbar=cbar,\n",
        "        xticklabels=categories,\n",
        "        yticklabels=categories,\n",
        "    )\n",
        "\n",
        "    if xyplotlabels:\n",
        "        plt.ylabel(\"True label\")\n",
        "        plt.xlabel(\"Predicted label\" + stats_text)\n",
        "    else:\n",
        "        plt.xlabel(stats_text)\n",
        "\n",
        "    if title:\n",
        "      plt.title(title)"
      ],
      "metadata": {
        "id": "WXSEBY_GJeZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def get_preds(dataloader, model, device = 'cpu'):\n",
        "  \n",
        "  all_labels = torch.tensor([])\n",
        "  all_preds = torch.tensor([])\n",
        "\n",
        "  model.eval()\n",
        "  for i, batch in enumerate(dataloader):\n",
        "\n",
        "      input_ids = batch[0].to(device)\n",
        "      input_masks = batch[1].to(device)\n",
        "      labels = batch[2].to(device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        result = model(input_ids, token_type_ids = None, attention_mask = input_masks, labels = labels, return_dict = True)\n",
        "\n",
        "      loss = result.loss\n",
        "      logits = result.logits.detach().cpu()\n",
        "      labels = labels.cpu()\n",
        "\n",
        "      preds = torch.argmax(logits, axis = 1).flatten()\n",
        "      labels = labels.flatten()\n",
        "\n",
        "      all_labels = torch.cat((all_labels, labels), dim=0)\n",
        "      all_preds = torch.cat((all_preds, preds), dim=0)\n",
        "\n",
        "  return all_labels, all_preds"
      ],
      "metadata": {
        "id": "jDuE-OlmHDmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels, all_preds = get_preds(train_dataloader, model, device)\n",
        "cm = confusion_matrix(all_labels, all_preds)"
      ],
      "metadata": {
        "id": "-sevG0kvlKOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_confusion_heatmap(cm, figsize=(12,8))"
      ],
      "metadata": {
        "id": "UNKf-IkYKc7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "roc_auc_score(all_labels, all_preds)"
      ],
      "metadata": {
        "id": "-wiYujTtK62l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is weird is that the model directly losses accuracy when we train it. It should gain in accuracy when we train it on a dowstream task. "
      ],
      "metadata": {
        "id": "6GshFvF1KF3S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The val loss is increasing way too much, it's overfitting. \n",
        "What we should do :\n",
        "\n",
        "- [x] Track the learning rate\n",
        "- [x] Call the scheduler after the validation step\n",
        "- [ ] Try different warmup steps\n",
        "- [x] Change the scheduler type\n",
        "- [x] Train on all data before submission"
      ],
      "metadata": {
        "id": "_RnyWaNdo6iJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make a submission"
      ],
      "metadata": {
        "id": "B-nwOvnzkASO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv(\"/content/drive/MyDrive/Machine Learning/Datasets/Disaster Tweets/test.csv\")"
      ],
      "metadata": {
        "id": "0dU62EQMkBS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "tweets = test_data['text'].to_list()\n",
        "\n",
        "for tweet in tweets:\n",
        "  output_dict = tokenizer.encode_plus(tweet, add_special_tokens=True, max_length=90, padding='max_length', return_attention_mask=True, return_tensors='pt')\n",
        "  input_ids.append(output_dict.input_ids)\n",
        "  attention_masks.append(output_dict.attention_mask)\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)"
      ],
      "metadata": {
        "id": "IfNJEPVulsBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
        "\n",
        "dataset = TensorDataset(input_ids, attention_masks)\n",
        "\n",
        "test_dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = False)"
      ],
      "metadata": {
        "id": "52Qq2ORFl4KO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds = torch.tensor([])\n",
        "\n",
        "model.eval()\n",
        "for i, batch in enumerate(test_dataloader):\n",
        "\n",
        "  input_ids = batch[0].to(device)\n",
        "  input_masks = batch[1].to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    result = model(input_ids, token_type_ids = None, attention_mask = input_masks, return_dict = True)\n",
        "\n",
        "    logits = result.logits.detach().cpu()\n",
        "\n",
        "    preds = torch.argmax(logits, axis = 1).flatten()\n",
        "\n",
        "    all_preds = torch.cat((all_preds, preds), dim=0)"
      ],
      "metadata": {
        "id": "8-WxnowLmej7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = test_data['id']\n",
        "preds = pd.DataFrame(list(all_preds.type(torch.int)), columns = ['target'])\n",
        "res = pd.merge(ids, preds, left_index = True, right_index = True)"
      ],
      "metadata": {
        "id": "Tb9QLktXnudu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res.to_csv(\"/content/drive/MyDrive/Machine Learning/Datasets/Disaster Tweets/res.csv\", sep = \",\", index = False)"
      ],
      "metadata": {
        "id": "NJmf2DAdovMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis of tweets wrongly classified"
      ],
      "metadata": {
        "id": "qFDu93dGNBRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds, all_labels = get_preds(train_dataloader, model, device)"
      ],
      "metadata": {
        "id": "Msd0cO41NAck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_preds = (all_preds != all_labels)"
      ],
      "metadata": {
        "id": "ipubwzzMO4Fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_preds = np.array(wrong_preds)"
      ],
      "metadata": {
        "id": "mCUH0mv4O_oI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_tweets = data[wrong_preds]"
      ],
      "metadata": {
        "id": "yUaRWnSzPMbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_tweets['pred'] = (wrong_tweets['target'] + 1) % 2"
      ],
      "metadata": {
        "id": "-En4XJMwQIrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_tweets"
      ],
      "metadata": {
        "id": "4ThvBtsOQb8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Possible improvements"
      ],
      "metadata": {
        "id": "FaZevBtQRl1W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* To improve the model performance we could set a treshold that maximises the val accuracy rather than just using argmax, which is equivalent to threshold 50%\n",
        "* Create an ensemble learning architecture"
      ],
      "metadata": {
        "id": "ZNISlMTGRtUa"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "4f0a451b91d21e89423ec86b823c013ebf520754bdcd7b6442031c0152fc2aaf"
      }
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}